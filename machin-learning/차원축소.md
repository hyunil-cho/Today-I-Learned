
# 차원축소

  매우 많은 피처고 구성된 다차원 데이터 세트의 차원을 축호, 새로운 차원의 데이터 세트를 생성하는 것

# Why?

1. 차원의 증가할수록(피처가 증가) 데이터 간의 거리가 멀어지고, 희소한 구조를 가지게 됨
2. 적은 수의 피처로 학습된 모델의 성능이 일반적으로 더 좋음
3. 특히 선형 회귀와 같이, 선형 모델에서는 피처간의 상관관계가 높을 경우, '다중 공선성 문제'로 모델의 성능이 떨어짐
4. 더 직관적으로 데이터를 해석할 수 있음
5. 데이터의 크기를 줄여, 더 효율적으로 분석이 가능

# 종류
1. 피처 선택(feature selection) : 특정 피처에 강한 종속성을 가지는 불필요한 피처는 삭제하고, 데이터의 특징을 나타내는 주요 피처만 남김
2. 피처 추출(feature extraction) : 기존 피처를 저차원의 중요 피처로 압축해서 추출. 이때 생성되는 데이터는 기존과 전혀 다른 데이터

# 알고리즘 종류
1. PCA
2. SVD
3. NMF

### '다중 공선성 문제'란?
> 피처(독립 변수)들 사이에 강한 상관관계가 있을 때 생기는 문제로, 어떤 피처가 Y값에 큰 영향을 주었는지 파악하기 어려움
>>상관 계수 행렬(Correlation Matrix) 확인</br>
>>VIF (Variance Inflation Factor) 값 확인

#
